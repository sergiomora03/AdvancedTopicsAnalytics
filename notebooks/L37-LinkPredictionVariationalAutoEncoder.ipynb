{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiomora03/AdvancedTopicsAnalytics/blob/main/notebooks/L37-LinkPredictionVariationalAutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qs9wmH6Jwt5"
      },
      "source": [
        "# Predicting Links with Graph Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip install pyg_lib --no-index -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "id": "77TTuS59g8OC",
        "outputId": "4ac289ac-5e73-496d-d726-69b538b71ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyg_lib\n",
            "Successfully installed pyg_lib-0.4.0+pt26cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6muoc6CEld7m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# !pip install -q torch-scatter~=2.1.0 torch-sparse~=0.6.16 torch-cluster~=1.6.0 torch-spline-conv~=1.2.1 torch-geometric==2.2.0 -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3ZIbJFS9ubN"
      },
      "source": [
        "## Graph Autoencoder (VAE) and Variational Graph Autoencoder (VGAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EgqVUSiulquq",
        "outputId": "ee4f0afa-abf0-4a69-c55b-82cd11b00730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False),\n",
        "])\n",
        "\n",
        "dataset = Planetoid('.', name='Cora', transform=transform)\n",
        "\n",
        "train_data, val_data, test_data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hc0ZiEn1lqkq"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv, VGAE\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dim_in, 2 * dim_out)\n",
        "        self.conv_mu = GCNConv(2 * dim_out, dim_out)\n",
        "        self.conv_logstd = GCNConv(2 * dim_out, dim_out)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaKaQxpYmC_5",
        "outputId": "28af0ac0-d6fa-4d5d-8dfd-12826519a87c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 | Loss: 3.5316 | Val AUC: 0.7096 | Val AP: 0.7263\n",
            "Epoch 50 | Loss: 1.3308 | Val AUC: 0.6791 | Val AP: 0.7021\n",
            "Epoch 100 | Loss: 1.1734 | Val AUC: 0.7123 | Val AP: 0.7188\n",
            "Epoch 150 | Loss: 1.0896 | Val AUC: 0.7704 | Val AP: 0.7765\n",
            "Epoch 200 | Loss: 1.0188 | Val AUC: 0.8219 | Val AP: 0.8294\n",
            "Epoch 250 | Loss: 0.9957 | Val AUC: 0.8297 | Val AP: 0.8370\n",
            "Epoch 300 | Loss: 0.9947 | Val AUC: 0.8403 | Val AP: 0.8485\n",
            "Test AUC: 0.8403 | Test AP 0.8485\n"
          ]
        }
      ],
      "source": [
        "model = VGAE(Encoder(dataset.num_features, 16)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "    loss = model.recon_loss(z, train_data.pos_edge_label_index) + (1 / train_data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
        "\n",
        "for epoch in range(301):\n",
        "    loss = train()\n",
        "    val_auc, val_ap = test(test_data)\n",
        "    if epoch % 50 == 0:\n",
        "        print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')\n",
        "\n",
        "test_auc, test_ap = test(test_data)\n",
        "print(f'Test AUC: {test_auc:.4f} | Test AP {test_ap:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D48lyZw49ubO",
        "outputId": "2891cd73-4d6f-4d18-96c0-79127ee8aea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7073, 0.6852, 0.7411,  ..., 0.4672, 0.7128, 0.7544],\n",
              "        [0.6852, 0.6937, 0.7601,  ..., 0.4569, 0.7294, 0.7507],\n",
              "        [0.7411, 0.7601, 0.8413,  ..., 0.4392, 0.8095, 0.8255],\n",
              "        ...,\n",
              "        [0.4672, 0.4569, 0.4392,  ..., 0.5175, 0.4502, 0.4488],\n",
              "        [0.7128, 0.7294, 0.8095,  ..., 0.4502, 0.7800, 0.7947],\n",
              "        [0.7544, 0.7507, 0.8255,  ..., 0.4488, 0.7947, 0.8245]],\n",
              "       grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "z = model.encode(test_data.x, test_data.edge_index)\n",
        "Ahat = torch.sigmoid(z @ z.T)\n",
        "Ahat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Wa0uAv9ubO"
      },
      "source": [
        "## SEAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tNNO18ePLd1W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from scipy.sparse.csgraph import shortest_path\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Conv1d, MaxPool1d, Linear, Dropout, BCEWithLogitsLoss\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, aggr\n",
        "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XqlCeawwm0Pp",
        "outputId": "2a06039a-b091-4a5a-dda1-3d7113c31948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488], neg_edge_label=[4488], neg_edge_label_index=[2, 4488])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Load Cora dataset\n",
        "transform = RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)\n",
        "dataset = Planetoid('.', name='Cora', transform=transform)\n",
        "train_data, val_data, test_data = dataset[0]\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tCSfv3PSMQ-e"
      },
      "outputs": [],
      "source": [
        "def seal_processing(dataset, edge_label_index, y):\n",
        "    data_list = []\n",
        "\n",
        "    for src, dst in edge_label_index.t().tolist():\n",
        "        sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph([src, dst], 2, dataset.edge_index, relabel_nodes=True)\n",
        "        src, dst = mapping.tolist()\n",
        "\n",
        "        # Remove target link from the subgraph\n",
        "        mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
        "        mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
        "        sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
        "\n",
        "        # Double-radius node labeling (DRNL)\n",
        "        src, dst = (dst, src) if src > dst else (src, dst)\n",
        "        adj = to_scipy_sparse_matrix(sub_edge_index, num_nodes=sub_nodes.size(0)).tocsr()\n",
        "\n",
        "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
        "        adj_wo_src = adj[idx, :][:, idx]\n",
        "\n",
        "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
        "        adj_wo_dst = adj[idx, :][:, idx]\n",
        "\n",
        "        # Calculate the distance between every node and the source target node\n",
        "        d_src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src)\n",
        "        d_src = np.insert(d_src, dst, 0, axis=0)\n",
        "        d_src = torch.from_numpy(d_src)\n",
        "\n",
        "        # Calculate the distance between every node and the destination target node\n",
        "        d_dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1)\n",
        "        d_dst = np.insert(d_dst, src, 0, axis=0)\n",
        "        d_dst = torch.from_numpy(d_dst)\n",
        "\n",
        "        # Calculate the label z for each node\n",
        "        dist = d_src + d_dst\n",
        "        z = 1 + torch.min(d_src, d_dst) + dist // 2 * (dist // 2 + dist % 2 - 1)\n",
        "        z[src], z[dst], z[torch.isnan(z)] = 1., 1., 0.\n",
        "        z = z.to(torch.long)\n",
        "\n",
        "        # Concatenate node features and one-hot encoded node labels (with a fixed number of classes)\n",
        "        node_labels = F.one_hot(z, num_classes=200).to(torch.float)\n",
        "        node_emb = dataset.x[sub_nodes]\n",
        "        node_x = torch.cat([node_emb, node_labels], dim=1)\n",
        "\n",
        "        # Create data object\n",
        "        data = Data(x=node_x, z=z, edge_index=sub_edge_index, y=y)\n",
        "        data_list.append(data)\n",
        "\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1iPBfn1LLip-"
      },
      "outputs": [],
      "source": [
        "# Enclosing subgraphs extraction\n",
        "train_pos_data_list = seal_processing(train_data, train_data.pos_edge_label_index, 1)\n",
        "train_neg_data_list = seal_processing(train_data, train_data.neg_edge_label_index, 0)\n",
        "\n",
        "val_pos_data_list = seal_processing(val_data, val_data.pos_edge_label_index, 1)\n",
        "val_neg_data_list = seal_processing(val_data, val_data.neg_edge_label_index, 0)\n",
        "\n",
        "test_pos_data_list = seal_processing(test_data, test_data.pos_edge_label_index, 1)\n",
        "test_neg_data_list = seal_processing(test_data, test_data.neg_edge_label_index, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dU_P2-JlR55j"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_pos_data_list + train_neg_data_list\n",
        "val_dataset = val_pos_data_list + val_neg_data_list\n",
        "test_dataset = test_pos_data_list + test_neg_data_list\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OyuODuSqP6iu"
      },
      "outputs": [],
      "source": [
        "class DGCNN(torch.nn.Module):\n",
        "    def __init__(self, dim_in, k=30):\n",
        "        super().__init__()\n",
        "\n",
        "        # GCN layers\n",
        "        self.gcn1 = GCNConv(dim_in, 32)\n",
        "        self.gcn2 = GCNConv(32, 32)\n",
        "        self.gcn3 = GCNConv(32, 32)\n",
        "        self.gcn4 = GCNConv(32, 1)\n",
        "\n",
        "        # Global sort pooling\n",
        "        self.global_pool = aggr.SortAggregation(k=k)\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = Conv1d(1, 16, 97, 97)\n",
        "        self.conv2 = Conv1d(16, 32, 5, 1)\n",
        "        self.maxpool = MaxPool1d(2, 2)\n",
        "\n",
        "        # Dense layers\n",
        "        self.linear1 = Linear(352, 128)\n",
        "        self.dropout = Dropout(0.5)\n",
        "        self.linear2 = Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Graph Convolutional Layers\n",
        "        h1 = self.gcn1(x, edge_index).tanh()\n",
        "        h2 = self.gcn2(h1, edge_index).tanh()\n",
        "        h3 = self.gcn3(h2, edge_index).tanh()\n",
        "        h4 = self.gcn4(h3, edge_index).tanh()\n",
        "        h = torch.cat([h1, h2, h3, h4], dim=-1)\n",
        "\n",
        "        # 2. Global sort pooling\n",
        "        h = self.global_pool(h, batch)\n",
        "\n",
        "        # 3. Traditional convolutional and dense layers\n",
        "        h = h.view(h.size(0), 1, h.size(-1))\n",
        "        h = self.conv1(h).relu()\n",
        "        h = self.maxpool(h)\n",
        "        h = self.conv2(h).relu()\n",
        "        h = h.view(h.size(0), -1)\n",
        "        h = self.linear1(h).relu()\n",
        "        h = self.dropout(h)\n",
        "        h = self.linear2(h).sigmoid()\n",
        "\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcivDBP4PjDx",
        "outputId": "c179d3c0-9411-43b0-c4a8-2f046e8a7052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 | Loss: 0.7022 | Val AUC: 0.6884 | Val AP: 0.6953\n",
            "Epoch  1 | Loss: 0.6430 | Val AUC: 0.7592 | Val AP: 0.7916\n",
            "Epoch  2 | Loss: 0.6125 | Val AUC: 0.7597 | Val AP: 0.7946\n",
            "Epoch  3 | Loss: 0.6081 | Val AUC: 0.7588 | Val AP: 0.7958\n",
            "Epoch  4 | Loss: 0.6053 | Val AUC: 0.7608 | Val AP: 0.7962\n",
            "Epoch  5 | Loss: 0.6032 | Val AUC: 0.7627 | Val AP: 0.7966\n",
            "Epoch  6 | Loss: 0.6018 | Val AUC: 0.7644 | Val AP: 0.7911\n",
            "Epoch  7 | Loss: 0.5996 | Val AUC: 0.7670 | Val AP: 0.7940\n",
            "Epoch  8 | Loss: 0.5979 | Val AUC: 0.7641 | Val AP: 0.7890\n",
            "Epoch  9 | Loss: 0.5969 | Val AUC: 0.7653 | Val AP: 0.7908\n",
            "Epoch 10 | Loss: 0.5966 | Val AUC: 0.7626 | Val AP: 0.7900\n",
            "Epoch 11 | Loss: 0.5948 | Val AUC: 0.7633 | Val AP: 0.7913\n",
            "Epoch 12 | Loss: 0.5942 | Val AUC: 0.7639 | Val AP: 0.7850\n",
            "Epoch 13 | Loss: 0.5939 | Val AUC: 0.7646 | Val AP: 0.7856\n",
            "Epoch 14 | Loss: 0.5926 | Val AUC: 0.7655 | Val AP: 0.7864\n",
            "Epoch 15 | Loss: 0.5923 | Val AUC: 0.7638 | Val AP: 0.7822\n",
            "Epoch 16 | Loss: 0.5914 | Val AUC: 0.7621 | Val AP: 0.7811\n",
            "Epoch 17 | Loss: 0.5918 | Val AUC: 0.7606 | Val AP: 0.7798\n",
            "Epoch 18 | Loss: 0.5906 | Val AUC: 0.7624 | Val AP: 0.7792\n",
            "Epoch 19 | Loss: 0.5912 | Val AUC: 0.7598 | Val AP: 0.7697\n",
            "Epoch 20 | Loss: 0.5901 | Val AUC: 0.7644 | Val AP: 0.7858\n",
            "Epoch 21 | Loss: 0.5898 | Val AUC: 0.7629 | Val AP: 0.7812\n",
            "Epoch 22 | Loss: 0.5896 | Val AUC: 0.7636 | Val AP: 0.7860\n",
            "Epoch 23 | Loss: 0.5888 | Val AUC: 0.7626 | Val AP: 0.7837\n",
            "Epoch 24 | Loss: 0.5884 | Val AUC: 0.7645 | Val AP: 0.7886\n",
            "Epoch 25 | Loss: 0.5890 | Val AUC: 0.7639 | Val AP: 0.7842\n",
            "Epoch 26 | Loss: 0.5874 | Val AUC: 0.7632 | Val AP: 0.7844\n",
            "Epoch 27 | Loss: 0.5880 | Val AUC: 0.7644 | Val AP: 0.7887\n",
            "Epoch 28 | Loss: 0.5871 | Val AUC: 0.7639 | Val AP: 0.7879\n",
            "Epoch 29 | Loss: 0.5879 | Val AUC: 0.7661 | Val AP: 0.7950\n",
            "Epoch 30 | Loss: 0.5864 | Val AUC: 0.7664 | Val AP: 0.7917\n",
            "Test AUC: 0.7718 | Test AP 0.7882\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DGCNN(train_dataset[0].num_features).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "criterion = BCEWithLogitsLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = criterion(out.view(-1), data.y.to(torch.float))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "\n",
        "    return total_loss / len(train_dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    y_pred, y_true = [], []\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        y_pred.append(out.view(-1).cpu())\n",
        "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
        "\n",
        "    auc = roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
        "    ap = average_precision_score(torch.cat(y_true), torch.cat(y_pred))\n",
        "\n",
        "    return auc, ap\n",
        "\n",
        "for epoch in range(31):\n",
        "    loss = train()\n",
        "    val_auc, val_ap = test(val_loader)\n",
        "    print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')\n",
        "\n",
        "test_auc, test_ap = test(test_loader)\n",
        "print(f'Test AUC: {test_auc:.4f} | Test AP {test_ap:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "book",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "3556630122da5213751af4465d61fcf5a52cd22515d400aee51118aaa1721248"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}